{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief notebook to answer the question:\n",
    "# \"Which job title am I actually doing in my current position\"\n",
    "### <i>A quick data exploration of: </i> <b>Data Scientist vs. Software Engineer</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-01\n",
    "Justin Gosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS IS NOTEBOOK II\n",
    "### Vectorization & Machine Learning Model Building & Prediction\n",
    "Go <a href=\"http://nbviewer.jupyter.org/github/JustinGOSSES/WhichJobTitle/blob/master/Which_Job_Title_Are_You-PartI.ipynb\">here</a> for notebook part I.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Some libraries we'll be using\n",
    "#### Pandas and Numpy for working with data structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#### Requests for loading webpages\n",
    "import requests\n",
    "#### BeautifulSoup for some very small scraping (not really data mining as we're only getting human-level data back)\n",
    "from bs4 import BeautifulSoup \n",
    "#### Regular expressions for text cleaning\n",
    "import re\n",
    "#### Visualization via the Vega library\n",
    "from vega3 import Vega\n",
    "#### Writing and reading to files via JSON\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new this notebook, we're also importing several libraries for machine-learning, which we'll do above each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV\n",
    "## Convert json jobs results into array for numerical only area machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with open('data/new_array_of_jobs_orig.json') as json_data:\n",
    "    new_array_of_jobs_ml = json.load(json_data)\n",
    "    print(len(new_array_of_jobs_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(new_array_of_jobs_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Takes in the job array called 'new_array_of_jobs_ml' from the json 'new_array_of_jobs_orig.json'\n",
    "#### And creates two files: 1) list of list of counts for each skill, which will now be features, and 2) list of lables\n",
    "#### 0 = data scientist\n",
    "#### 1 = software engineer\n",
    "def convertJSONtoDataArray(jsonData):\n",
    "    holder_of_features = []\n",
    "    holder_of_labels = []\n",
    "    for job in jsonData:\n",
    "        skill_holder = []\n",
    "        for count in job[\"word_counts\"]:\n",
    "            skill_holder.append(int(count[\"count\"]))\n",
    "        \n",
    "        holder_of_features.append(skill_holder)\n",
    "        if job[\"job\"] == \"Software Engineer\":\n",
    "            holder_of_labels.append(0)\n",
    "        elif job[\"job\"] == \"Data Scientist\":\n",
    "            holder_of_labels.append(1)\n",
    "        else:\n",
    "            print(\"THERE IS A PROBLEM YOU HAVE A WEIRD JOB TITLE\")\n",
    "    return holder_of_features,holder_of_labels       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holder_of_features,holder_of_labels = convertJSONtoDataArray(new_array_of_jobs_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(len(holder_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(len(holder_of_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertLabelsToText(lab):\n",
    "    if lab == 0:\n",
    "            return \"Software Engineer\"\n",
    "    elif lab == 1:\n",
    "            return \"Data Scientist\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### functino that takes in a array of labels in terms of 0 and 1 and converts it to array of Software Engineer or Data Scientist text lables\n",
    "#### This will be used below to convert numerical labels to text\n",
    "def convertLabelsToTextArray(holder_of_labels):\n",
    "    text_labels = []\n",
    "    for lab in holder_of_labels:\n",
    "        text_labels.append(convertLabelsToText(lab))\n",
    "    return text_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer']\n"
     ]
    }
   ],
   "source": [
    "text_labels = convertLabelsToTextArray(holder_of_labels)\n",
    "print(text_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### save skill counts as features in a json\n",
    "with open('data/holder_of_features.json', 'w') as outfile:\n",
    "    json.dump(holder_of_features, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### save labels(0 or 1) in a json\n",
    "with open('data/holder_of_labels.json', 'w') as outfile:\n",
    "    json.dump(holder_of_labels, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V\n",
    "### Machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### importing from scikit-learn http://scikit-learn.org/\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(holder_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8582417582417583"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Set training (X) and label data (y)\n",
    "X = holder_of_features\n",
    "y = holder_of_labels\n",
    "\n",
    "#### Make a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.883882783882784"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Make a Random Forest Classifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=6, random_state=0)\n",
    "scores_RF = cross_val_score(clf_rf, X, y)\n",
    "scores_RF.mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283272283272282"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Make a Random Forest Classifier\n",
    "clf_ET = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "scores_ET = cross_val_score(clf_ET, X, y)\n",
    "scores_ET.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y) \n",
    "KNeighborsClassifier(...)\n",
    "print(neigh.predict_proba([holder_of_features[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884004884004884"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_KNN1 = cross_val_score(neigh, X, y)\n",
    "scores_KNN1.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Examining results of KNN classification\n",
    "def correctOrNotKNN(neigh,holder_of_features,holder_of_labels):\n",
    "    counter = 0\n",
    "    for eachJob in holder_of_features:\n",
    "        result_list = neigh.predict_proba([eachJob])[0].tolist()\n",
    "        if result_list[1] > result_list[0]:\n",
    "            prediction = \"Data Scientist\"\n",
    "        elif result_list[1] < result_list[0]:\n",
    "            prediction = \"Software Engineer\"\n",
    "        else:\n",
    "            print(\"check data !!!!\")\n",
    "        text_label = convertLabelsToText(holder_of_labels[counter])\n",
    "        if text_label == prediction:\n",
    "            score = True\n",
    "        else:\n",
    "            score = False\n",
    "        print(counter,prediction,score,result_list)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Data Scientist True [0.0, 1.0]\n",
      "1 Data Scientist True [0.0, 1.0]\n",
      "2 Data Scientist True [0.3333333333333333, 0.6666666666666666]\n",
      "3 Data Scientist True [0.3333333333333333, 0.6666666666666666]\n",
      "4 Data Scientist True [0.0, 1.0]\n",
      "5 Data Scientist True [0.3333333333333333, 0.6666666666666666]\n",
      "6 Data Scientist True [0.0, 1.0]\n",
      "7 Data Scientist True [0.0, 1.0]\n",
      "8 Data Scientist True [0.0, 1.0]\n",
      "9 Data Scientist True [0.0, 1.0]\n",
      "10 Software Engineer True [1.0, 0.0]\n",
      "11 Software Engineer True [0.6666666666666666, 0.3333333333333333]\n",
      "12 Software Engineer True [1.0, 0.0]\n",
      "13 Software Engineer True [1.0, 0.0]\n",
      "14 Software Engineer True [1.0, 0.0]\n",
      "15 Software Engineer True [1.0, 0.0]\n",
      "16 Software Engineer True [1.0, 0.0]\n",
      "17 Software Engineer True [1.0, 0.0]\n",
      "18 Software Engineer True [1.0, 0.0]\n",
      "19 Software Engineer True [1.0, 0.0]\n",
      "20 Software Engineer True [0.6666666666666666, 0.3333333333333333]\n",
      "21 Software Engineer True [0.6666666666666666, 0.3333333333333333]\n",
      "22 Software Engineer True [1.0, 0.0]\n",
      "23 Software Engineer True [1.0, 0.0]\n",
      "24 Software Engineer True [0.6666666666666666, 0.3333333333333333]\n",
      "25 Software Engineer True [0.6666666666666666, 0.3333333333333333]\n",
      "26 Data Scientist True [0.0, 1.0]\n",
      "27 Data Scientist True [0.0, 1.0]\n",
      "28 Data Scientist True [0.0, 1.0]\n",
      "29 Software Engineer False [0.6666666666666666, 0.3333333333333333]\n",
      "30 Data Scientist True [0.0, 1.0]\n",
      "31 Data Scientist True [0.0, 1.0]\n",
      "32 Data Scientist True [0.0, 1.0]\n",
      "33 Software Engineer False [0.6666666666666666, 0.3333333333333333]\n",
      "34 Data Scientist True [0.0, 1.0]\n",
      "35 Data Scientist True [0.0, 1.0]\n",
      "36 Software Engineer True [0.6666666666666666, 0.3333333333333333]\n",
      "37 Software Engineer True [1.0, 0.0]\n",
      "38 Software Engineer True [1.0, 0.0]\n",
      "39 Software Engineer True [1.0, 0.0]\n",
      "40 Software Engineer True [1.0, 0.0]\n",
      "41 Software Engineer True [1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#### Examining results of KNN classification\n",
    "correctOrNotKNN(neigh,holder_of_features,holder_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(holder_of_features)\n",
    "y = np.array(holder_of_labels)\n",
    "from sklearn.svm import SVC\n",
    "clf_SVC1 = SVC()\n",
    "clf_SVC1.fit(X, y) \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407814407814408"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_SVC1 = cross_val_score(clf_SVC1, X, y)\n",
    "scores_SVC1.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Examining results of KNN classification\n",
    "def correctOrNotSVM(clf,holder_of_features,holder_of_labels):\n",
    "    counter = 0\n",
    "    for eachJob in holder_of_features:\n",
    "        result_list = clf.predict([eachJob])[0].tolist()\n",
    "        #print(\"result_list\",result_list)\n",
    "        if result_list == 1:\n",
    "            prediction = \"Data Scientist\"\n",
    "        elif result_list == 0:\n",
    "            prediction = \"Software Engineer\"\n",
    "        else:\n",
    "            print(\"check data !!!!\")\n",
    "        text_label = convertLabelsToText(holder_of_labels[counter])\n",
    "        if text_label == prediction:\n",
    "            score = True\n",
    "        else:\n",
    "            score = False\n",
    "        #print(counter,prediction,score,result_list)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = correctOrNotSVM(clf_SVC1,holder_of_features,holder_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### try with rbf kernal\n",
    "import numpy as np\n",
    "X = np.array(holder_of_features)\n",
    "y = np.array(holder_of_labels)\n",
    "from sklearn.svm import SVC\n",
    "clf_rbf1 = SVC()\n",
    "clf_rbf1.fit(X, y) \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407814407814408"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_SVC1 = cross_val_score(clf_rbf1, X, y)\n",
    "scores_SVC1.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVCresults = correctOrNotSVM(clf_rbf1,holder_of_features,holder_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poly kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### try with rbf kernal\n",
    "import numpy as np\n",
    "X = np.array(holder_of_features)\n",
    "y = np.array(holder_of_labels)\n",
    "from sklearn.svm import SVC\n",
    "clf_poly1 = SVC()\n",
    "clf_poly1.fit(X, y) \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407814407814408"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_poly1 = cross_val_score(clf_poly1, X, y)\n",
    "scores_poly1.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVCresults = correctOrNotSVM(clf_pol,holder_of_features,holder_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VI\n",
    "## Now lets prepare text from my resume and see what it predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science, Data Visualization, and Web Developer\n",
      "Offers two years of experience on the NASA data analytics team and nine years of experience in the oil industry as a geoscientist. Has successfully delivered projects in the machine learning, artificial intelligence, data visualization, and software engineering spaces working with clients in domains as diverse as geology, finance, human resources, and astronaut training. Seeks a position that applies my data analytics and programming skills to build new tools and capabilities.\n",
      "\n",
      "Computer Language, Database, Web-development & Machine-Learning Skills: \n",
      "•\tLanguage, DB & Cloud - Python, R, Java, JavaScript, Sed/Awk, Prostgresql, Neo4J, AWS System admin.\n",
      "•\tA.I. - Alexa skill development, CMU Sphinx speech-to-text, & Raspberry Pi IoT development.\n",
      "•\tML - Scikit-learn, TensorFlow, NumPy, Theano, and Keras, Weka, MATLAB, K-means, SVM, & Decision Trees.\n",
      "•\tWeb – Flask.py, Node.js, JQuery.js, Angular.js, & React.js, HTML, CSS, & Wordpress.\n",
      "•\tData visualization - d3.js, three.js, Seaborn, ggplot2, Bokeh, Vega, Tableau, & AR.js (augmented reality).\n",
      "Communication and Leadership Experience: \t\n",
      "•\tCo-lead for Houston Data Visualization Meet-up (https://houstondatavis.github.io/)\n",
      "•\tRice Data Sci. Conf. 2017 Talk - “Practical Considerations for Data Science Consulting in a Large Organization“\n",
      "•\tExperienced leading discussions with clients and subject matter experts.\n",
      "•\tActed as company representative to research consortium and led software vender evaluations. \n",
      "•\tCollaborated with drilling engineers to adjust forward predictions in real-time during drilling operations.\n",
      "•\tManaged and coached interns and junior staff. Co-organizer of 500+ person conference.\n",
      "Data Analytics and Machine-learning Experience:\n",
      "•\tPredicted fluid connectivity in gas field development leveraging multiple linear regression and neural networks.\n",
      "•\tPredicted well-log lithology using support vector machine and boosted trees machine-learning methods.\n",
      "•\tDelivered study that quantified how well conventional oil and gas exploration methods predicted the spatial distribution of economically successful wells in the major unconventional gas fields across the United States.\n",
      "•\tDeveloped Alexa skill & ran offline speech-to-text study for A.I. use-case. NASA IoT working group member.\n",
      "•\tBuilt a graph database of dependencies scraped from internal code repos to gain insight into developer skills.\n",
      "•\tActed as stratigraphy and sedimentology subject matter expert and consultant within center of excellence. \n",
      "•\tApplied geostatistics in building 3D model simulations of subsurface fluid flow and resource size calculations used in a billion-dollar investment decision.\n",
      "Data Visualization and Web Development Experience: \n",
      "•\tMap making & spatial analysis using ArcGIS desktop, ArcGIS online, leaflet.js, mapbox.gl, geopandas.py, etc.\n",
      "•\tSystem admin (linux) & webpage admin for microservices and client facing webpage servers\n",
      "•\tDeveloped web-based data visualizations with d3.js, Tableau, and various JavaScript and Python libraries.\n",
      "•\tCreated an interactive visualization to show how NASA’s strategic goals and objectives map to spending.\n",
      "•\tBuilt a project management dashboard that drastically improved the ability of executives to see trends.\n",
      "•\tVisualized aggregate & device specific patterns in network traffic from an Internet of Things WiFi network.\n",
      "\n",
      "Professional Experience\n",
      "Valador Inc., Software Developer, (2016-current):\n",
      "Push adoption of new technologies through consulting & proof-of-concept projects across a range of domains and clients as a member of the NASA OCIO Technology & Innovation Division Data Analytics lab.\n",
      "BP Exploration and Production, Geologist (2006-2015) & intern (2005): \n",
      "Worked in multidisciplinary teams to analyze data, make predictions, communicate results, and enable decisions. \n",
      "Education\n",
      "Masters of Science, Geoscience, 3.7 GPA – 2006 – University of Wisconsin – Madison\n",
      "Bachelors of Science, Geoscience, Honors, – 2004 – Franklin and Marshall College, Pennsylvania\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### open the resume text from a saved txt file\n",
    "f = open('data/Justin_Resume.txt','r')\n",
    "text_ugly = f.read()\n",
    "print(text_ugly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Clean the ugly resume text\n",
    "def cleanResume(resume):\n",
    "    resume = resume.lower()\n",
    "    resume = re.sub('[^a-zA-Z0-9 \\n\\.]', '', resume)\n",
    "    resume = resume.replace('\\n',' ')\n",
    "    resume = resume.replace('\\r',' ')\n",
    "    print(resume)\n",
    "    return resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data science data visualization and web developer offers two years of experience on the nasa data analytics team and nine years of experience in the oil industry as a geoscientist. has successfully delivered projects in the machine learning artificial intelligence data visualization and software engineering spaces working with clients in domains as diverse as geology finance human resources and astronaut training. seeks a position that applies my data analytics and programming skills to build new tools and capabilities.  computer language database webdevelopment  machinelearning skills  language db  cloud  python r java javascript sedawk prostgresql neo4j aws system admin. a.i.  alexa skill development cmu sphinx speechtotext  raspberry pi iot development. ml  scikitlearn tensorflow numpy theano and keras weka matlab kmeans svm  decision trees. web  flask.py node.js jquery.js angular.js  react.js html css  wordpress. data visualization  d3.js three.js seaborn ggplot2 bokeh vega tableau  ar.js augmented reality. communication and leadership experience  colead for houston data visualization meetup httpshoustondatavis.github.io rice data sci. conf. 2017 talk  practical considerations for data science consulting in a large organization experienced leading discussions with clients and subject matter experts. acted as company representative to research consortium and led software vender evaluations.  collaborated with drilling engineers to adjust forward predictions in realtime during drilling operations. managed and coached interns and junior staff. coorganizer of 500 person conference. data analytics and machinelearning experience predicted fluid connectivity in gas field development leveraging multiple linear regression and neural networks. predicted welllog lithology using support vector machine and boosted trees machinelearning methods. delivered study that quantified how well conventional oil and gas exploration methods predicted the spatial distribution of economically successful wells in the major unconventional gas fields across the united states. developed alexa skill  ran offline speechtotext study for a.i. usecase. nasa iot working group member. built a graph database of dependencies scraped from internal code repos to gain insight into developer skills. acted as stratigraphy and sedimentology subject matter expert and consultant within center of excellence.  applied geostatistics in building 3d model simulations of subsurface fluid flow and resource size calculations used in a billiondollar investment decision. data visualization and web development experience  map making  spatial analysis using arcgis desktop arcgis online leaflet.js mapbox.gl geopandas.py etc. system admin linux  webpage admin for microservices and client facing webpage servers developed webbased data visualizations with d3.js tableau and various javascript and python libraries. created an interactive visualization to show how nasas strategic goals and objectives map to spending. built a project management dashboard that drastically improved the ability of executives to see trends. visualized aggregate  device specific patterns in network traffic from an internet of things wifi network.  professional experience valador inc. software developer 2016current push adoption of new technologies through consulting  proofofconcept projects across a range of domains and clients as a member of the nasa ocio technology  innovation division data analytics lab. bp exploration and production geologist 20062015  intern 2005  worked in multidisciplinary teams to analyze data make predictions communicate results and enable decisions.  education masters of science geoscience 3.7 gpa  2006  university of wisconsin  madison bachelors of science geoscience honors  2004  franklin and marshall college pennsylvania \n"
     ]
    }
   ],
   "source": [
    "#### I'm leaving in the periods as they are needed to capture some skills\n",
    "clean_resume_text = cleanResume(text_ugly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertJSONtoDataArray(jsonData):\n",
    "    holder_of_features = []\n",
    "    holder_of_labels = []\n",
    "    for job in jsonData:\n",
    "        skill_holder = []\n",
    "        for count in job[\"word_counts\"]:\n",
    "            skill_holder.append(int(count[\"count\"]))\n",
    "        \n",
    "        holder_of_features.append(skill_holder)\n",
    "        if job[\"job\"] == \"Software Engineer\":\n",
    "            holder_of_labels.append(0)\n",
    "        elif job[\"job\"] == \"Data Scientist\":\n",
    "            holder_of_labels.append(1)\n",
    "        else:\n",
    "            print(\"THERE IS A PROBLEM YOU HAVE A WEIRD JOB TITLE\")\n",
    "    return holder_of_features,holder_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resume_obj = {\"job\":'Data Scientist',\"full_title\":'Data Scientist',\"url\":\"none\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clean_resume_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFeaturesForTest(resume_obj,clean_resume_text,array_of_skills):\n",
    "    results_array = []\n",
    "    for skill in array_of_skills:\n",
    "            instance = clean_resume_text.count(skill)\n",
    "            results_array.append({\"skill\":skill,\"count\":instance})\n",
    "    resume_obj[\"word_counts\"] = results_array\n",
    "    return resume_obj\n",
    "        \n",
    "# results_array = []\n",
    "#         for skill in array_of_skills:\n",
    "#             instance = noSpecial.count(skill)\n",
    "#             results_array.append({\"skill\":skill,\"count\":instance})\n",
    "#         job[\"word_counts\"] = results_array\n",
    "#         new_array_of_jobs.append(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n"
     ]
    }
   ],
   "source": [
    "#### Get array of skills again\n",
    "with open('data/array_of_skills.json') as json_data:\n",
    "    array_of_skills = json.load(json_data)\n",
    "    print(len(array_of_skills)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_job_skills_OfResume = createFeaturesForTest(resume_obj,clean_resume_text,array_of_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj_job_skills_OfResume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertJSONtoDataArray(jsonData):\n",
    "    holder_of_features = []\n",
    "    holder_of_labels = []\n",
    "    for job in jsonData:\n",
    "        skill_holder = []\n",
    "        for count in job[\"word_counts\"]:\n",
    "            skill_holder.append(int(count[\"count\"]))\n",
    "        \n",
    "        holder_of_features.append(skill_holder)\n",
    "        if job[\"job\"] == \"Software Engineer\":\n",
    "            holder_of_labels.append(0)\n",
    "        elif job[\"job\"] == \"Data Scientist\":\n",
    "            holder_of_labels.append(1)\n",
    "        else:\n",
    "            print(\"THERE IS A PROBLEM YOU HAVE A WEIRD JOB TITLE\")\n",
    "    return holder_of_features,holder_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n"
     ]
    }
   ],
   "source": [
    "holder_of_features_resume,holder_of_labels_resume = convertJSONtoDataArray([obj_job_skills_OfResume])\n",
    "print(len(holder_of_features_resume[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder_of_labels_resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best results seemed to come from the Extra Forest Classifier, so we'll use that model to see what job it thinks I do based on my resume\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For refresher, this is the Extra Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283272283272282"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Make a Extra Forest Classifier\n",
    "clf_ET = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "scores_ET = cross_val_score(clf_ET, X, y)\n",
    "clf_ET.fit(X, y)\n",
    "scores_ET.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run the features associated with my resume through it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_num = clf_ET.predict(holder_of_features_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertLabelsToText(prediction_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which means I'm likely a data scientist\n",
    "#### ...at least according to the skils on my resume and a small sample of job descriptions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*and I apologize for all the poor code, this was a silly experiment and not really worth cleaning at this time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
